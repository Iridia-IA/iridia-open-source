{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\"\"\"\n",
    "In previous examples we've annotated the `messages` state key\n",
    "with the default `operator.add` or `+` reducer, which always\n",
    "appends new messages to the end of the existing messages array.\n",
    "\n",
    "Now, to support replacing existing messages, we annotate the\n",
    "`messages` key with a customer reducer function, which replaces\n",
    "messages with the same `id`, and appends them otherwise.\n",
    "\"\"\"\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    # assign ids to messages that don't have them\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    # merge the new messages with the existing messages\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            # replace any existing messages with the same id\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            # append any new messages to the end\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before=[\"action\"] #INTERRUPT IS USEFUL FOR THE USER TO INTERACT. \n",
    "        )\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        print(state)\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Whats the weather in SF?', id='e24f5b5b-29f6-4de4-9d67-9e99c5547838'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', id='e24f5b5b-29f6-4de4-9d67-9e99c5547838'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef3df77-d02b-6e59-8001-cc44b26f57e7'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-07-09T13:31:03.532296+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef3df77-c2fb-64fd-8000-9eb234ee3382'}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('action',)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://www.accuweather.com/en/us/san-francisco/94103/september-weather/347629', 'content': 'Avg. 71°. 55°. Temperature Graph. °F.Missing:  09/07/2024'}, {'url': 'https://www.weather.com/weather/tenday/l/94110:4:US', 'content': 'tenDayWeather-San Francisco, CA. asOfTime. Today. 70°/55°. 4%. Sun 07 | day. 70°. 4%. W 16 mph. Plenty of sunshine. High near 70F. Winds W at 10 to 20 mph.'}]\", name='tavily_search_results_json', tool_call_id='call_3JYAu0DuEHAc29H4hRUCyJRF')]}\n",
      "{'messages': [HumanMessage(content='Whats the weather in SF?', id='e24f5b5b-29f6-4de4-9d67-9e99c5547838'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content=\"[{'url': 'https://www.accuweather.com/en/us/san-francisco/94103/september-weather/347629', 'content': 'Avg. 71°. 55°. Temperature Graph. °F.Missing:  09/07/2024'}, {'url': 'https://www.weather.com/weather/tenday/l/94110:4:US', 'content': 'tenDayWeather-San Francisco, CA. asOfTime. Today. 70°/55°. 4%. Sun 07 | day. 70°. 4%. W 16 mph. Plenty of sunshine. High near 70F. Winds W at 10 to 20 mph.'}]\", name='tavily_search_results_json', id='8e80af6e-6a27-4695-b06f-8ba072fea21e', tool_call_id='call_3JYAu0DuEHAc29H4hRUCyJRF'), AIMessage(content='The weather in San Francisco today is around 70°F with a low of 55°F. It is expected to be sunny with a slight breeze.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 337, 'total_tokens': 368}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f625bbc-00df-41de-887c-7068d5231f9d-0', usage_metadata={'input_tokens': 337, 'output_tokens': 31, 'total_tokens': 368})]}\n",
      "{'messages': [AIMessage(content='The weather in San Francisco today is around 70°F with a low of 55°F. It is expected to be sunny with a slight breeze.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 337, 'total_tokens': 368}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f625bbc-00df-41de-887c-7068d5231f9d-0', usage_metadata={'input_tokens': 337, 'output_tokens': 31, 'total_tokens': 368})]}\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', id='e24f5b5b-29f6-4de4-9d67-9e99c5547838'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d87dbdbe-304d-414c-b563-f314d13056a1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_3JYAu0DuEHAc29H4hRUCyJRF'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content=\"[{'url': 'https://www.accuweather.com/en/us/san-francisco/94103/september-weather/347629', 'content': 'Avg. 71°. 55°. Temperature Graph. °F.Missing:  09/07/2024'}, {'url': 'https://www.weather.com/weather/tenday/l/94110:4:US', 'content': 'tenDayWeather-San Francisco, CA. asOfTime. Today. 70°/55°. 4%. Sun 07 | day. 70°. 4%. W 16 mph. Plenty of sunshine. High near 70F. Winds W at 10 to 20 mph.'}]\", name='tavily_search_results_json', id='8e80af6e-6a27-4695-b06f-8ba072fea21e', tool_call_id='call_3JYAu0DuEHAc29H4hRUCyJRF'), AIMessage(content='The weather in San Francisco today is around 70°F with a low of 55°F. It is expected to be sunny with a slight breeze.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 337, 'total_tokens': 368}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f625bbc-00df-41de-887c-7068d5231f9d-0', usage_metadata={'input_tokens': 337, 'output_tokens': 31, 'total_tokens': 368})]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef3df78-0396-6772-8003-3c52ede128dd'}}, metadata={'source': 'loop', 'step': 3, 'writes': {'llm': {'messages': [AIMessage(content='The weather in San Francisco today is around 70°F with a low of 55°F. It is expected to be sunny with a slight breeze.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 337, 'total_tokens': 368}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f625bbc-00df-41de-887c-7068d5231f9d-0', usage_metadata={'input_tokens': 337, 'output_tokens': 31, 'total_tokens': 368})]}}}, created_at='2024-07-09T13:31:08.923685+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef3df77-f8a0-6c35-8002-ca21ab0ac0be'}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
